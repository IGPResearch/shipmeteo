{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import metpy.calc as mcalc\n",
    "import metpy.units as metunits\n",
    "# local module\n",
    "import mypaths\n",
    "\n",
    "import json\n",
    "\n",
    "from ipywidgets import interact\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weatherpack_variable_aliases.json', 'r') as fj:\n",
    "    vrbl_aliases = json.load(fj)\n",
    "vrbl_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpk_usage = pd.read_csv('weatherpack_usage.txt',\n",
    "                        sep='\\s+',\n",
    "                        na_values='NA',\n",
    "                        parse_dates=['date'],\n",
    "                        index_col='date',\n",
    "#                         dtype=dict(wpk2=str),\n",
    "                        ).fillna('')\n",
    "wpk_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpk_latlon_parser(s):\n",
    "    latlon_re = re.compile(r'''\n",
    "# Latitude part\n",
    "(?P<lat_hem>[NS])\\s*\n",
    "(?P<lat_deg>[0-9]{2})\\s*\n",
    "(?P<lat_min>[0-9]{1,2}\\.[0-9]{3})\\s*\n",
    "\n",
    "# Longitude part\n",
    "(?P<lon_hem>[EW])\\s*\n",
    "(?P<lon_deg>[0-9]{3})\\s*\n",
    "(?P<lon_min>[0-9]{1,2}\\.[0-9]{3})''', re.X)\n",
    "    \n",
    "    m = re.match(latlon_re, s)\n",
    "    if m:\n",
    "        if m.group('lat_hem') == 'S':\n",
    "            lat_factor = -1\n",
    "        else:\n",
    "            lat_factor = 1\n",
    "\n",
    "        if m.group('lon_hem') == 'W':\n",
    "            lon_factor = -1\n",
    "        else:\n",
    "            lon_factor = 1\n",
    "\n",
    "        lat = lat_factor * (float(m.group('lat_deg')) + float(m.group('lat_min')) / 60)\n",
    "        lon = lon_factor * (float(m.group('lon_deg')) + float(m.group('lon_min')) / 60)\n",
    "    lat, lon = np.nan, np.nan\n",
    "    \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_range = (pd.date_range(start=date,\n",
    "#                             freq='T',\n",
    "#                             end=date+timedelta(hours=23, minutes=59, seconds=59))\n",
    "#               .to_series()\n",
    "#               .to_frame(name='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputdir = mypaths.wpk_dir / '2_Leg' / 'TRUEWIND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = inputdir / f'Wpk_st04@{date:%Y_%m_%d}.txt'\n",
    "# print(fname.exists())\n",
    "# # fname = inputdir / f'data_3_{date:%Y%m%d_%H}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_dataframe_time(df, date, freq='1T', end='auto'):\n",
    "    if end == 'auto':\n",
    "        end = date + timedelta(hours=23, minutes=59, seconds=59)\n",
    "    time_range = (pd.date_range(start=date,\n",
    "                                freq=freq,\n",
    "                                end=end)\n",
    "                      .to_series()\n",
    "                      .to_frame(name='time'))\n",
    "\n",
    "    labels = time_range.index\n",
    "    df = (pd.concat([df, time_range])\n",
    "          .sort_index()\n",
    "          .interpolate(method='values', limit=1)\n",
    "          .drop('time', axis=1))\n",
    "    df.index = df.index.rename('time')\n",
    "    df = df.loc[df.index.intersection(labels)]\n",
    "    return df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wpk_daily(topdir, date, wpk_id):\n",
    "    wpk_id = str(wpk_id)\n",
    "    assert wpk_id in ['2', '4'], 'Works only for WeatherPacks  No. 2 or 4'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    if wpk_id == '2':\n",
    "        fname = topdir / f'Wpk_st0{wpk_id}@{date:%Y_%m_%d}.txt'\n",
    "        if fname.exists():\n",
    "            df = pd.read_csv(fname, parse_dates=[[1, 2]], index_col=0,\n",
    "                             date_parser=lambda x: datetime.strptime(x, '%y/%m/%d %H:%M:%S'))\n",
    "            # df.index.rename('DateTime', inplace=True)\n",
    "            df[['latitude', 'longitude']] = (df['Ship position']\n",
    "                                             .map(wpk_latlon_parser, na_action='ignore')\n",
    "                                             .apply(pd.Series)\n",
    "                                             .rename(mapper={0: 'latitude', 1: 'longitude'}, axis=1))\n",
    "            df = df.drop(labels=['Unit ID', 'Ship position'], axis=1)\n",
    "    elif wpk_id == '4':\n",
    "        fname = topdir / f'AR{date:%y%m%d}.00{wpk_id}'\n",
    "        if fname.exists():\n",
    "            df = pd.read_csv(fname, skiprows=1, sep='\\t', parse_dates=[['date', 'time']], index_col='date_time',\n",
    "                             date_parser=lambda x: datetime.strptime(x, '%y/%m/%d %H:%M:%S'))        \n",
    "    \n",
    "    if len(df) > 0:\n",
    "        # Convert wind speed and direction to u and v components\n",
    "        df = add_wind_components(df)\n",
    "        # Interpolate to minute time intervals\n",
    "        df = interp_dataframe_time(df, date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wind_components(df):\n",
    "    for alias in vrbl_aliases['ws']:\n",
    "        try:\n",
    "            wspd = df[alias]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for alias in vrbl_aliases['wd']:\n",
    "        try:\n",
    "            wdir = df[alias]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    df['u'], df['v'] = mcalc.get_wind_components(wspd.values * metunits.units('m/s'),\n",
    "                                                 wdir.values * metunits.units('degrees'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wpk_hourly(topdir, date, wpk_id):\n",
    "    def date_parser(s):\n",
    "        return datetime.strptime(s[:-4], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    wpk_id = str(wpk_id)\n",
    "    assert wpk_id in ['3', '4'], 'Works only for WeatherPacks  No. 3 or 4'\n",
    "    \n",
    "    # Read (raw?) data stored in hourly files and concatenate into a DataFrame for the whole day\n",
    "    df = pd.DataFrame()\n",
    "    for h in range(24):\n",
    "        fname = topdir / wpk_id / f'{date:%Y}' / f'{date:%m}' / f'{date:%d}' / f'data_{wpk_id}_{date:%Y%m%d}_{h:02d}.log'\n",
    "        time_col_name = ' zeno_date zeno_time zeno_timezone'\n",
    "        if fname.exists():\n",
    "            df_next = pd.read_csv(fname,\n",
    "                                  error_bad_lines=False, warn_bad_lines=False,\n",
    "                                  index_col=time_col_name,\n",
    "                                  parse_dates=[time_col_name],\n",
    "                                  date_parser=date_parser)\n",
    "            df = pd.concat([df, df_next])\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Convert wind speed and direction to u and v components\n",
    "        df = add_wind_components(df)\n",
    "        # Interpolate to minute time intervals\n",
    "        df = interp_dataframe_time(df, date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = pd.datetime(2018, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpk_usage = wpk_usage.applymap(lambda x: 't,rh,ws,wd,p,sr,u,v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame()\n",
    "\n",
    "for date in tqdm(wpk_usage.index):\n",
    "    wpk_vars = wpk_usage.loc[date]\n",
    "    data = dict()\n",
    "\n",
    "    if wpk_vars.wpk2:\n",
    "        vrbls = wpk_vars.wpk2.split(',')\n",
    "        topdir = mypaths.wpk_dir / 'WP02'\n",
    "        df = read_wpk_daily(topdir, date, '2')\n",
    "\n",
    "        for vrbl in vrbls:\n",
    "            for alias in vrbl_aliases[vrbl]:\n",
    "                try:\n",
    "                    data[vrbl+'_wpk2'] = df[alias]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    if wpk_vars.wpk3:\n",
    "        df = read_wpk_hourly(mypaths.wpk_dir, date, '3')\n",
    "        vrbls = wpk_vars.wpk3.split(',')\n",
    "        if len(df) > 0:\n",
    "            for vrbl in vrbls:\n",
    "                for alias in vrbl_aliases[vrbl]:\n",
    "                    try:\n",
    "                        data[vrbl+'_wpk3'] = df[alias]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "    if wpk_vars.wpk4:\n",
    "        vrbls = wpk_vars.wpk4.split(',')\n",
    "        if date < datetime(2018, 2, 27):\n",
    "            df = read_wpk_hourly(mypaths.wpk_dir, date, '4')\n",
    "        else:\n",
    "            df = read_wpk_daily(mypaths.wpk_dir / '2_Leg' / 'FORESTAR', date, '4')\n",
    "        if len(df) > 0:\n",
    "            for vrbl in vrbls:\n",
    "                for alias in vrbl_aliases[vrbl]:\n",
    "                    try:\n",
    "                        data[vrbl+'_wpk4'] = df[alias]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "    df_full = pd.concat([df_full, pd.DataFrame(data)], sort=True)\n",
    "# df_full.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# @interact(v=df_full.columns, day=(0, len(wpk_usage)))\n",
    "# def fun(v, day=0):\n",
    "#     ax.cla()\n",
    "#     df_full[v].plot(ax=ax, linewidth=2, marker='.')\n",
    "#     ax.set_xlim(wpk_usage.index[0]+timedelta(days=day), wpk_usage.index[0]+timedelta(days=day+1))\n",
    "#     fig.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flag = df_full.rename(columns={k: k+'_flag' for k in df_full.columns.values}).copy().applymap(lambda x: 0)\n",
    "# df_flag = pd.read_csv(sorted(Path('.').glob('weatherpack_data_flag_*.csv'))[-1], index_col='time', parse_dates=['time'])\n",
    "df_flag = pd.read_csv('weatherpack_data_flag.csv', index_col='time', parse_dates=['time'])\n",
    "df_flag.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "tt = [wpk_usage.index[0], wpk_usage.index[-1]]\n",
    "\n",
    "dd = widgets.Dropdown(\n",
    "    options=df_full.columns,\n",
    "    description='Variable:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "w = widgets.IntRangeSlider(\n",
    "    value=[0, 24 * 60],\n",
    "    min=0,\n",
    "    max=24 * 60,\n",
    "    step=1,\n",
    "    description='Hours',\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "slider = widgets.IntSlider(\n",
    "    description='Days',\n",
    "    value=0,\n",
    "    step=1,\n",
    "    min=0,\n",
    "    max=len(wpk_usage)\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Click Me!\")\n",
    "\n",
    "caption = widgets.Label(value='Blah')\n",
    "\n",
    "debug_view = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "@debug_view.capture(clear_output=True)\n",
    "def plotter(vrbl, tdelta0, tdelta1):\n",
    "    ax.cla()\n",
    "    ax.set_title(vrbl, loc='left')\n",
    "    tt[0] = wpk_usage.index[0] + tdelta0\n",
    "    tt[1] = wpk_usage.index[0] + tdelta1\n",
    "    caption.value = f'{df_full[vrbl].loc[tt[0]:tt[1]].min():2.1f}\\n{df_full[vrbl].loc[tt[0]:tt[1]].max():2.1f}'\n",
    "    df_full[vrbl].loc[tt[0]:tt[1]].plot(ax=ax, linewidth=0, marker='.')\n",
    "    df_full[dd.value][df_flag[dd.value+'_flag']==1].loc[tt[0]:tt[1]].plot(ax=ax, linestyle='', marker='x', color='r')\n",
    "#     fig.tight_layout()\n",
    "\n",
    "# debug_view = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "@debug_view.capture(clear_output=True)\n",
    "def handle_dropdown_change(change):\n",
    "    td0 = timedelta(days=slider.value, minutes=w.value[0])\n",
    "    td1 = timedelta(days=slider.value, minutes=w.value[1])\n",
    "    plotter(change.new, td0, td1)\n",
    "\n",
    "def handle_slider_change(change):\n",
    "    td0 = timedelta(days=change.new, minutes=w.value[0])\n",
    "    td1 = timedelta(days=change.new, minutes=w.value[1])\n",
    "    plotter(dd.value, td0, td1)\n",
    "    \n",
    "def handle_range_change(change):\n",
    "    td0 = timedelta(days=slider.value, minutes=change.new[0])\n",
    "    td1 = timedelta(days=slider.value, minutes=change.new[1])\n",
    "    plotter(dd.value, td0, td1)\n",
    "    \n",
    "@debug_view.capture(clear_output=True)\n",
    "def on_button_clicked(b):\n",
    "    df_flag[dd.value+'_flag'].loc[tt[0]:tt[1]] = 1\n",
    "    df_full[dd.value].loc[tt[0]:tt[1]].plot(ax=ax, linestyle='', marker='x', color='r')\n",
    "\n",
    "slider.observe(handle_slider_change, names='value')\n",
    "w.observe(handle_range_change, names='value')\n",
    "# slider.observe(handle_range_change, names='value')\n",
    "button.on_click(on_button_clicked)\n",
    "dd.observe(handle_dropdown_change, names='value')\n",
    "\n",
    "display(widgets.HBox([dd, w, slider, button, caption]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[dd.value][df_flag[dd.value+'_flag']==1].loc[tt[0]:tt[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flag.to_csv(f'./weatherpack_data_flag_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flag.to_csv(f'./weatherpack_data_flag_{datetime.now():%Y%m%d%H%M%S}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:igp]",
   "language": "python",
   "name": "conda-env-igp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
