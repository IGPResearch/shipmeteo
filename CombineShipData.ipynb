{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import xarray as xr\n",
    "\n",
    "import metpy.calc as mcalc\n",
    "import metpy.units as metunits\n",
    "# local module\n",
    "import mypaths\n",
    "\n",
    "import json\n",
    "\n",
    "from ipywidgets import interact\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_logs import AllianceComposite, MSG_LIST, average_ds_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weatherpack_variable_aliases.json', 'r') as fj:\n",
    "    vrbl_aliases = json.load(fj)\n",
    "vrbl_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpk_usage = pd.read_csv('weatherpack_usage.txt',\n",
    "                        sep='\\s+',\n",
    "                        na_values='NA',\n",
    "                        parse_dates=['date'],\n",
    "                        index_col='date',\n",
    "#                         dtype=dict(wpk2=str),\n",
    "                        ).fillna('')\n",
    "wpk_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrbl_attrs = {\n",
    "    't': {\n",
    "        'name': 'air_temperature',\n",
    "        'attrs': {\n",
    "            'standard_name': 'air_temperature',\n",
    "            'long_name': 'Air Temperature',\n",
    "            'units': 'degree_celsius'\n",
    "        }\n",
    "    },\n",
    "    'p': {\n",
    "        'scale': 100,\n",
    "        'name': 'air_pressure',\n",
    "        'attrs': {\n",
    "            'standard_name': 'air_pressure',\n",
    "            'long_name': 'Air Pressure',\n",
    "            'units': 'Pa'\n",
    "        }\n",
    "    },\n",
    "    'rh': {\n",
    "        'scale': 1e-2,\n",
    "        'name': 'relative_humidity',\n",
    "        'attrs': {\n",
    "            'standard_name': 'relative_humidity',\n",
    "            'long_name': 'Relative Humidity',\n",
    "            'units': '1'\n",
    "        }\n",
    "    },\n",
    "    'sr': {\n",
    "        'name': 'solar_irradiance',\n",
    "        'attrs': {\n",
    "            'standard_name': 'solar_irradiance',\n",
    "            'long_name': 'Solar Irradiance',\n",
    "            'units': 'W m-2'\n",
    "        }\n",
    "    },\n",
    "    'u': {\n",
    "        'name': 'u',\n",
    "        'attrs': {\n",
    "            'standard_name': 'eastward_wind',\n",
    "            'long_name': 'U component of wind',\n",
    "            'units': 'm s-1'\n",
    "        },\n",
    "        'dep': ['wd', 'ws']\n",
    "    },\n",
    "    'v': {\n",
    "        'name': 'v',\n",
    "        'attrs': {\n",
    "            'standard_name': 'northward_wind',\n",
    "            'long_name': 'V component of wind',\n",
    "            'units': 'm s-1'\n",
    "        },\n",
    "        'dep': ['wd', 'ws']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpk_latlon_parser(s):\n",
    "    latlon_re = re.compile(r'''\n",
    "# Latitude part\n",
    "(?P<lat_hem>[NS])\\s*\n",
    "(?P<lat_deg>[0-9]{2})\\s*\n",
    "(?P<lat_min>[0-9]{1,2}\\.[0-9]{3})\\s*\n",
    "\n",
    "# Longitude part\n",
    "(?P<lon_hem>[EW])\\s*\n",
    "(?P<lon_deg>[0-9]{3})\\s*\n",
    "(?P<lon_min>[0-9]{1,2}\\.[0-9]{3})''', re.X)\n",
    "    \n",
    "    m = re.match(latlon_re, s)\n",
    "    if m:\n",
    "        if m.group('lat_hem') == 'S':\n",
    "            lat_factor = -1\n",
    "        else:\n",
    "            lat_factor = 1\n",
    "\n",
    "        if m.group('lon_hem') == 'W':\n",
    "            lon_factor = -1\n",
    "        else:\n",
    "            lon_factor = 1\n",
    "\n",
    "        lat = lat_factor * (float(m.group('lat_deg')) + float(m.group('lat_min')) / 60)\n",
    "        lon = lon_factor * (float(m.group('lon_deg')) + float(m.group('lon_min')) / 60)\n",
    "    lat, lon = np.nan, np.nan\n",
    "    \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_range = (pd.date_range(start=date,\n",
    "#                             freq='T',\n",
    "#                             end=date+timedelta(hours=23, minutes=59, seconds=59))\n",
    "#               .to_series()\n",
    "#               .to_frame(name='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputdir = mypaths.wpk_dir / '2_Leg' / 'TRUEWIND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = inputdir / f'Wpk_st04@{date:%Y_%m_%d}.txt'\n",
    "# print(fname.exists())\n",
    "# # fname = inputdir / f'data_3_{date:%Y%m%d_%H}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_dataframe_time(df, date, freq='1T', end='auto'):\n",
    "    if end == 'auto':\n",
    "        end = date + timedelta(hours=23, minutes=59, seconds=59)\n",
    "    time_range = (pd.date_range(start=date,\n",
    "                                freq=freq,\n",
    "                                end=end)\n",
    "                      .to_series()\n",
    "                      .to_frame(name='time'))\n",
    "\n",
    "    labels = time_range.index\n",
    "    df = (pd.concat([df, time_range])\n",
    "          .sort_index()\n",
    "          .interpolate(method='values', limit=1)\n",
    "          .drop('time', axis=1))\n",
    "    df.index = df.index.rename('time')\n",
    "    df = df.loc[df.index.intersection(labels)]\n",
    "    return df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wind_components(df):\n",
    "    wspd = None\n",
    "    wdir = None\n",
    "    for alias in vrbl_aliases['ws']:\n",
    "        try:\n",
    "            wspd = df[alias]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for alias in vrbl_aliases['wd']:\n",
    "        try:\n",
    "            wdir = df[alias]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    if wspd is not None and wdir is not None:\n",
    "        df['u'], df['v'] = mcalc.get_wind_components(wspd.values * metunits.units('m/s'),\n",
    "                                                     wdir.values * metunits.units('degrees'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wpk_daily(topdir, date, wpk_id):\n",
    "    wpk_id = str(wpk_id)\n",
    "    assert wpk_id in ['2', '4'], 'Works only for WeatherPacks  No. 2 or 4'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    if wpk_id == '2':\n",
    "        fname = topdir / f'Wpk_st0{wpk_id}@{date:%Y_%m_%d}.txt'\n",
    "        if fname.exists():\n",
    "            df = pd.read_csv(fname, parse_dates=[[1, 2]], index_col=0,\n",
    "                             date_parser=lambda x: datetime.strptime(x, '%y/%m/%d %H:%M:%S'))\n",
    "            # df.index.rename('DateTime', inplace=True)\n",
    "            df[['latitude', 'longitude']] = (df['Ship position']\n",
    "                                             .map(wpk_latlon_parser, na_action='ignore')\n",
    "                                             .apply(pd.Series)\n",
    "                                             .rename(mapper={0: 'latitude', 1: 'longitude'}, axis=1))\n",
    "            df = df.drop(labels=['Unit ID', 'Ship position'], axis=1)\n",
    "    elif wpk_id == '4':\n",
    "        fname = topdir / f'AR{date:%y%m%d}.00{wpk_id}'\n",
    "        if fname.exists():\n",
    "            df = pd.read_csv(fname, skiprows=1, sep='\\t', parse_dates=[['date', 'time']], index_col='date_time',\n",
    "                             date_parser=lambda x: datetime.strptime(x, '%y/%m/%d %H:%M:%S'))        \n",
    "    \n",
    "    if len(df) > 0:\n",
    "        # Convert wind speed and direction to u and v components\n",
    "        df = add_wind_components(df)\n",
    "        # Interpolate to minute time intervals\n",
    "        df = interp_dataframe_time(df, date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wpk_hourly(topdir, date, wpk_id):\n",
    "    def date_parser(s):\n",
    "        return datetime.strptime(s[:-4], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    wpk_id = str(wpk_id)\n",
    "    assert wpk_id in ['3', '4'], 'Works only for WeatherPacks  No. 3 or 4'\n",
    "    \n",
    "    # Read (raw?) data stored in hourly files and concatenate into a DataFrame for the whole day\n",
    "    df = pd.DataFrame()\n",
    "    for h in range(24):\n",
    "        fname = topdir / wpk_id / f'{date:%Y}' / f'{date:%m}' / f'{date:%d}' / f'data_{wpk_id}_{date:%Y%m%d}_{h:02d}.log'\n",
    "        time_col_name = ' zeno_date zeno_time zeno_timezone'\n",
    "        if fname.exists():\n",
    "            df_next = pd.read_csv(fname,\n",
    "                                  error_bad_lines=False, warn_bad_lines=False,\n",
    "                                  index_col=time_col_name,\n",
    "                                  parse_dates=[time_col_name],\n",
    "                                  date_parser=date_parser)\n",
    "            df = pd.concat([df, df_next])\n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Convert wind speed and direction to u and v components\n",
    "        df = add_wind_components(df)\n",
    "        # Interpolate to minute time intervals\n",
    "        df = interp_dataframe_time(df, date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpk_usage = wpk_usage.applymap(lambda x: 't,rh,ws,wd,p,sr,u,v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = pd.datetime(2018, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame()\n",
    "\n",
    "for date in tqdm(wpk_usage.index):\n",
    "    wpk_vars = wpk_usage.loc[date]\n",
    "    data = dict()\n",
    "\n",
    "    if wpk_vars.wpk2:\n",
    "        vrbls = wpk_vars.wpk2.split(',')\n",
    "        topdir = mypaths.wpk_dir / 'WP02'\n",
    "        df = read_wpk_daily(topdir, date, '2')\n",
    "\n",
    "        for vrbl in vrbls:\n",
    "            for alias in vrbl_aliases[vrbl]:\n",
    "                try:\n",
    "                    data[vrbl+'_wpk2'] = df[alias]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    if wpk_vars.wpk3:\n",
    "        df = read_wpk_hourly(mypaths.wpk_dir, date, '3')\n",
    "        vrbls = wpk_vars.wpk3.split(',')\n",
    "        if len(df) > 0:\n",
    "            for vrbl in vrbls:\n",
    "                for alias in vrbl_aliases[vrbl]:\n",
    "                    try:\n",
    "                        data[vrbl+'_wpk3'] = df[alias]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "    if wpk_vars.wpk4:\n",
    "        vrbls = wpk_vars.wpk4.split(',')\n",
    "        if date < datetime(2018, 2, 27):\n",
    "            df = read_wpk_hourly(mypaths.wpk_dir, date, '4')\n",
    "        else:\n",
    "            df = read_wpk_daily(mypaths.wpk_dir / '2_Leg' / 'FORESTAR', date, '4')\n",
    "        if len(df) > 0:\n",
    "            for vrbl in vrbls:\n",
    "                for alias in vrbl_aliases[vrbl]:\n",
    "                    try:\n",
    "                        data[vrbl+'_wpk4'] = df[alias]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "    df_full = pd.concat([df_full, pd.DataFrame(data)], sort=True)\n",
    "# df_full.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flag = pd.read_csv('weatherpack_data_flag.csv', index_col='time', parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = df_full.to_xarray()\n",
    "ds_flag = df_flag.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_temp = (xr.open_dataset(mypaths.igp_data_dir / 'ALL0118_uctd' / 'igp_all0118_uctd.nc')\n",
    "            .sbe38_bow_temperature\n",
    "            .to_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_min = [1, 10, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weatherpack_notes.txt', 'r') as f:\n",
    "    wpk_notes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attrs = {\n",
    "    'title': 'NMEA, WeatherPack, and CTD Temperature data from IGP cruise (QC level 1)',\n",
    "    'summary': \"\"\"The dataset comprises data gathered during the IGP field campaign by several instruments on board NRV Alliance.\n",
    "The data are aligned in time: i.e. CTD and NMEA data (having originally 1 sec resolution) are averaged over 1 min intervals; Weatherpack data typically have 1 min resolution, but sometimes the timestamp is between two whole minute marks, so the data is interpolated to 1 min resolution for all days.\n",
    "There are large gaps in useful data from WeatherPacks due to incorrect set-up of Wpk 3 and 4 during cruise leg 1 and occasional freezing of sensors.\n",
    "Obviously incorrect values are flagged: e.g. <variable>_wpk<wpk_number>_flag = 1.\"\"\",\n",
    "    'keywords': 'igp,weatherpack,aws,nmea,ctd',\n",
    "    'conventions': 'CF-1.7,ACDD-1.3',\n",
    "    'history': f'Combined from different sources as the netCDF file at {datetime.utcnow():%Y-%m-%d %H:%M:%S} GMT by Denis Sergeev (University of East Anglia)',\n",
    "    'source': 'NMEA on board NRV Alliance; WeatherPacks 2, 3, 4; SBE38 temperature sensor',\n",
    "    'processing_level': 'no calibration performed',\n",
    "    'comment':  wpk_notes,\n",
    "    'date_created': f'{datetime.utcnow():%Y-%m-%d %H:%M:%S} GMT',\n",
    "    'institution': 'University of East Anglia, Woods Hole Oceanographic Institution',\n",
    "    'creator_name': 'Denis Sergeev',\n",
    "    'creator_email': 'd.sergeev@uea.ac.uk',\n",
    "    'creator_institution': 'University of East Anglia',\n",
    "    'project': 'The Iceland Greenland Seas Project (IGP)',\n",
    "    'coverage_content_type': 'physicalMeasurement',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = mypaths.igp_data_dir / 'wpk_nmea_ctd' / 'qc1'\n",
    "outdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillval = 1e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in tqdm(wpk_usage.index[40:]):\n",
    "    ds_dict = dict()\n",
    "\n",
    "    # NMEA data\n",
    "    fname = mypaths.igp_data_dir / 'nmea_logs' / f'{date:%Y%m%d}.log'\n",
    "    AC = AllianceComposite(fname, date)\n",
    "    try:\n",
    "        AC.process(MSG_LIST)\n",
    "        ds_nmea = AC.ds.rename({k: k + '_nmea' for k in AC.ds.data_vars})\n",
    "        ds_dict['nmea'] = ds_nmea\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "#     combined_ds.merge(ds_nmea, inplace=True)\n",
    "    # CTD data\n",
    "    try:\n",
    "        ds_dict['ctd'] = ctd_temp.sel(time=f'{date:%Y%m%d}')\n",
    "    except KeyError:\n",
    "        pass\n",
    "#     combined_ds = combined_ds.assign(sbe38_bow_temperature=ds_ctd.sbe38_bow_temperature)\n",
    "    # weatherpacks data\n",
    "    ds = ds_full.sel(time=f'{date:%Y%m%d}').merge(ds_flag.sel(time=f'{date:%Y%m%d}'))\n",
    "    for data_var in filter(lambda x: '_flag' not in x, ds.data_vars):\n",
    "        wpk_num = data_var[-1]\n",
    "        for vrbl, vdict in vrbl_attrs.items():\n",
    "            if vrbl == data_var.split('_wpk')[0]:\n",
    "                attrs = vdict['attrs'].copy()\n",
    "                attrs['long_name'] += f' from WeatherPack {wpk_num}'\n",
    "                scl = vdict.get('scl', 1)\n",
    "                flag_var = vdict.get('dep', data_var)\n",
    "        if isinstance(flag_var, list):\n",
    "            mask = np.zeros_like(ds[data_var], dtype=bool)\n",
    "            for fv in flag_var:\n",
    "                mask = np.bitwise_or(mask, (ds[fv+data_var[-5:]]==1))\n",
    "            ds.assign(**{data_var+'_flag': mask})\n",
    "        else:\n",
    "            mask = (ds[data_var+'_flag'] == 1)\n",
    "\n",
    "        ds[data_var][mask] = np.nan\n",
    "        ds[data_var] *= scl\n",
    "        ds[data_var].attrs.update(attrs)\n",
    "        \n",
    "    ds_dict['wpk'] = ds[[i for i in ds.data_vars\n",
    "                       if i[:2] not in ['wd', 'ws'] and not i.startswith('sr_wpk2')]]\n",
    "    \n",
    "\n",
    "        \n",
    "    for freq in tqdm(freqs_min):\n",
    "        pd_freq = pd.Timedelta(freq, 'm')  # in minutes\n",
    "        combined_ds = xr.Dataset(attrs=global_attrs)\n",
    "        for k, v in ds_dict.items():\n",
    "#             if (v.time[1] - v.time[0]).values < pd_freq.to_timedelta64():\n",
    "            if v.time.shape[0] > 0:\n",
    "                ds = (v.resample(time=pd_freq, keep_attrs=True)\n",
    "                      .reduce(np.nanmean, keep_attrs=True))\n",
    "                if k == 'wpk':\n",
    "                    ds = ds.drop(labels=[i for i in ds.data_vars\n",
    "                                         if i.endswith('_flag')])\n",
    "    #             else:\n",
    "    #                 ds = v\n",
    "                combined_ds.merge(ds, inplace=True)\n",
    "        date_attrs = {\n",
    "            'time_coverage_start': f'{np.nanmin(combined_ds.time).astype(\"datetime64[us]\").astype(datetime):%Y-%m-%dT%H:%M:%SZ}',\n",
    "            'time_coverage_end': f'{np.nanmax(combined_ds.time).astype(\"datetime64[us]\").astype(datetime):%Y-%m-%dT%H:%M:%SZ}',\n",
    "        }\n",
    "        date_attrs['time_coverage_resolution'] = f'{freq}min'\n",
    "        combined_ds.attrs.update(date_attrs)\n",
    "        combined_ds = combined_ds.fillna(fillval)\n",
    "        for data_var in combined_ds.data_vars:\n",
    "            combined_ds[data_var].attrs.update(_FillValue=fillval)\n",
    "\n",
    "        combined_ds.to_netcdf(path=outdir / f'wpk_nmea_ctd_qc1_{date:%Y%m%d}_{freq:02d}min.nc',\n",
    "                              encoding=dict(time=dict(units=f'seconds since {AC.TSTART:%Y-%m-%dT%H:%M:%S.%f}',\n",
    "                                            calendar='gregorian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:igp]",
   "language": "python",
   "name": "conda-env-igp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
